{"pages":[{"url":"/pages/about.html","text":"创e ，花名皓禹，原名张斌，计算机专业，从事运维、开发工作，业余讲师 2009年 从事linux运维工作 2010年 继续运维,兼职业余技术讲师 2011年 继续运维 2012年 开始DevOps 2013年 正式成为python程序猿 2014年 专注python web开发和app后端开发","tags":"about","title":"about"},{"url":"/pages/links.html","text":"晓的博客 峰云就她了 峰云就她了-51cto 灿哥的Blog the5fire的技术博客 FURION'S BLOG-思聪 陈李粮 流水理鱼-李爽 我友博客 Reboot运维开发 piglei's blog Vlix博客","tags":"pages","title":"links"},{"url":"/pytohn_ip_regex.html","text":"1 2 3 4 5 6 7 def _chk_ipaddr ( ipaddr ): IP_PATTERN = '&#94;((0|[1-9]\\d?|[0-1]\\d{2}|2[0-4]\\d|25[0-5])\\.){3}(0|[1-9]\\d?|[0-1]\\d{2}|2[0-4]\\d|25[0-5])$' if not ipaddr : return False ipcheck = re . compile ( IP_PATTERN , re . I ) return True if ipcheck . match ( ipaddr ) else False","tags":"python","title":"python中验证ip的有效性正则"},{"url":"/webchat_alarm.html","text":"最近公司业务上涨，报警频频发生，刚买的短信接口已经用一半了，这么下去肯定不是办法。现在都是移动互联网时代了，肯定得想点新办法，看着手机我想起了微信，这货要是能实现报警，问题不就解决了么？ 我抱着试一试的态度，在网上查找了一下，结果病就治好了…… 呃…… 电视广告看多了。 在网上查到了微信实现报警的方案，以我的理解分两种： 1.公众号，公众号使用模板信息可以给用户发送10w调每天的信息 2.企业号，给员工无限制的发送信息: 企业号的功能： 企业号适用于企业与员工或上下游供应链之间的沟通。 1、企业可以主动发消息给员工，消息量不受限制。 2、企业号出现在微信会话列表首层，在通讯录中有单独的分类。 3、可以自定义菜单。 4、拥有多个子号。 5、更加关注与安全，需要双方认证。 作为一个强迫症控，那肯定得用企业号啊，这里需要老板的支持，企业号不是自己能申请的，还好我老板高瞻远瞩，已经申请好了。（嘻嘻，希望老板能看到） 对企业号进行配置： 扫描二维码进行登录： https://qy.weixin.qq.com/ 配置企业号 登陆以后新建应用： 输入应用名称为监控报警就新建了一个叫做监控报警的应用，新建完成后，进入【应用中心】查看应用id， 这里后面要用。 设置管理员： 指定应用的管理员。点击设置-> 权限管理 -> 管理 -> 新建管理组 --> 添加管理员和权限。然后就会获得corpid 和 sceret。这里后面也要用。 开发 1、阅读开发文档。文档位置： 微信开发文档 我只读了建立连接、管理通讯录、发送消息。好了，发个报警够了，很简单。 2、建立连接获取access_token。 这个token是一个有有效时间的密钥用于后续操作认证。 Https请求方式: GET https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=id&corpsecret=secrect 正常情况下就会反馈一个json并得到access_token 根据文档获取玩access_token后就可以发送消息了。 我写的脚本代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/usr/bin/env python # coding:utf-8 import sys import urllib2 import time import json import requests reload ( sys ) sys . setdefaultencoding ( 'utf-8' ) title = sys . argv [ 2 ] # 位置参数获取title 适用于zabbix content = sys . argv [ 3 ] # 位置参数获取content 适用于zabbix class Token ( object ): # 获取token def __init__ ( self , corpid , corpsecret ): self . baseurl = 'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid={0}&corpsecret={1}' . format ( corpid , corpsecret ) self . expire_time = sys . maxint def get_token ( self ): if self . expire_time > time . time (): request = urllib2 . Request ( self . baseurl ) response = urllib2 . urlopen ( request ) ret = response . read () . strip () ret = json . loads ( ret ) if 'errcode' in ret . keys (): print >> ret [ 'errmsg' ], sys . stderr sys . exit ( 1 ) self . expire_time = time . time () + ret [ 'expires_in' ] self . access_token = ret [ 'access_token' ] return self . access_token def send_msg ( title , content ): # 发送消息 corpid = \"\" # 填写自己应用的 corpsecret = \"\" # 填写自己应用的 qs_token = Token ( corpid = corpid , corpsecret = corpsecret ) . get_token () url = \"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={0}\" . format ( qs_token ) payload = { \"touser\" : \"user1|user2\" , \"msgtype\" : \"text\" , \"agentid\" : \"3\" , \"text\" : { \"content\" : \"标题:{0} \\n 内容:{1}\" . format ( title , content ) }, \"safe\" : \"0\" } ret = requests . post ( url , data = json . dumps ( payload , ensure_ascii = False )) print ret . json () if __name__ == '__main__' : # print title, content send_msg ( title , content ) 参考文章： 微信公众平台企业号用于监控报警探究（python版本）","tags":"python","title":"实现微信报警"},{"url":"/python_telnet_huawei.html","text":"最近在研究华为防火墙，要搞个web版的程序来控制防火墙，那底层就需要用telnet或者snmp来控制设置，今天先共享下telnet的代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #coding=utf-8 import telnetlib import re import time HOST = '192.168.1.231' user = 'admin' password = 'admin' tn = telnetlib . Telnet ( HOST ) # tn.set_debuglevel(2) #开启调试模式 tn . expect ([ re . compile ( b \"Username:\" ),]) #用正则匹配Username tn . write ( user + \" \\n \" ) #匹配成功，输入user tn . expect ([ re . compile ( b \"Password:\" ),]) #同上 tn . write ( password + \" \\n \" ) #同上 time . sleep ( . 1 ) tn . read_until ( \"<HWJC.HL-DDoS.SDA>\" ) #如果读到<HWJC.HL-DDoS.SDA>提示符，执行下面命令 tn . write ( \"display clock \\n \" ) #输入命令 tn . read_until ( \"display clock\" ) #如果读到\"display clock\"，执行下面命令，这里的操作是在后面获取返回值的时候排除\"display clock\"这一行数据 time . sleep ( . 1 ) #延时以确保下调命令能读到数据 print tn . read_very_eager () #打印执行\"display clock\"的返回值 # tn.write(\"quit\\n\") #退出 # print tn.read_all() #获取全部返回值 tn . close () #关闭连接","tags":"python","title":"python通过telnet连接华为设备"},{"url":"/python_viode_4.html","text":"在大家看到这门课程的时候，这个视频已经让我传到51cto的学院上了，之前一直用七牛云存储做视频存放，结果超过免费标准，收费了然后给我账号封了，我很无奈所以想找个新的放视频的地方，最好是优酷，结果优酷审核总是很慢，所以我就选择了51cto。但是想观看51cto的这个课程需要花费5金币来购买，5金币也就是5元人民币，这也是我经过深思熟虑的事，一是这样会让我录制视频更有动力，二是大家看起来也会更珍惜。所以还是希望大家多少支持吧。毕竟大家看到我这幻灯片做的都对得起这个价格，哈哈哈…… 共享你的代码（二）课程知识点： 新需求 改变API后，兼容老用户 增加参数，满足新老用户 视频地址：请点击 共享你的代码（二）","tags":"python开发实践","title":"python开发实践(四)"},{"url":"/django_memory_out.html","text":"前两天工作需求，把python脚本从crontab的方式改成守护进程(daemon)，上线后发现，内存飙升，cpu飙高，程序直接死掉，让我伤心欲绝，郁郁寡欢，终日不得眠啊。开始以为是内存溢出用gc调试好久也看不出问题。由于项目使用了Django-ORM，所以开始怀疑是不是因为Django引发的性能问题。 搜索了一下关于django内存泄露的文章，这片文章 —— Django\"内存泄漏\"的问题 给我了启示: 文中第一条就提到:Make sure that you set DEBUG to False in settings.py，在DEBUG模式下，所有的SQL查询都会被保存在内存中.我顿时想起，由于我整个项目还在调试阶段，这个DEBUG变量是设置为True的 DEBUG设置为False后，内存泄漏的问题就不复存在了 可我整个项目还需要调试，不能就这么简单的关闭DEBUG模式，怎么办? 我一开始想在后台模块import settings后再重新设置DEBUG变量 下面分析一下脚本程序，import了Django的models,并且对数据库的数据做了轮询操作，所以执行大量的sql去读数据库的全部数据，由于线上DEBUG改成了True，所有的SQL查询保存在了内存中，这样导致内存飙高，好吧不得不说为了把脚本弄成守护进程方式，还用了个while True的死循环，虽然改成了while 1，但是心里还是怪怪的。 找到问题的原因，我就把DEBUG改成False重启一下,果然内存不再飙高，就此搞定。在此记录一下，解决线上问题的一个小思路。","tags":"python","title":"Django内存溢出"},{"url":"/python_obj_for_json.html","text":"有时候，在Django的model中,直接查询出来的orm对象，想直接转成json会报错： 1 TypeError is not JSON serializable 1 2 3 4 5 6 7 8 def convert_to_builtin_type ( obj ): # print 'default(', repr(obj), ')' # Convert objects to a dictionary of btheir representation d = { '__class__' : obj . __class__ . __name__ , '__module__' : obj . __module__ , } d . update ( obj . __dict__ ) return d 然后在函数中调用： 1 2 3 ip = Ip . objects . filter ( ip = ip ) context = { 'ip' : list ( ip )} return HttpResponse ( json . dumps ( context , ensure_ascii = False , indent = 4 , default = convert_to_builtin_type )) 如上先filter出ip=ip的条目保存在ip变量中，然后格式化下保存在context变量中。调用时放在default中。 如果喜欢pythonic，可以用下面lambda方式搞定： 1 return HttpResponse ( json . dumps ( context , ensure_ascii = False , indent = 4 , default = lambda o : o . __dict__ ))","tags":"python","title":"Python对象类型转换json的方法"},{"url":"/python_multi_for_break.html","text":"今天同事问我一个python面试题，关于python跳出多层循环，原来还真没用过，网上一查还真有点意思，下面记录一下： Python 本身没有\"break n\" 和\"goto\" 的语法，这也造成了Python 难以跳出多层（特定层数）循环。下面是几个跳出多层（特定层数）循环的tip。 1、自定义异常 1 2 3 4 5 6 7 8 9 10 11 12 class getoutofloop ( Exception ): pass try : for i in range ( 5 ): for j in range ( 5 ): for k in range ( 5 ): if i == j == k == 3 : raise getoutofloop () else : print i , '----' , j , '----' , k except getoutofloop : pass 2、封装为函数return 1 2 3 4 5 6 7 8 9 def test (): for i in range ( 5 ): for j in range ( 5 ): for k in range ( 5 ): if i == j == k == 3 : return else : print i , '----' , j , '----' , k test () 3、for ... else ... 用法 上面的两种都是只能跳出多层而不能跳出特定层数的循环，接下来的这个正是为了跳出特定层数的循环。 1 2 3 4 5 6 7 8 9 10 11 for i in range ( 5 ): for j in range ( 5 ): for k in range ( 5 ): if i == j == k == 3 : break else : print i , '----' , j , '----' , k else : continue break else : continue break else在 while和for 正常循环完成之后执行，和直接写在 while和for 之后没有区别，但是如果用break结束循环之后else就不会执行了。这也是个很新奇的做法。 才知道原来可以作为跳出多层循环用。不过要是有多次跳出不同层的循环的需求，也没辙了。","tags":"python","title":"python跳出多层循环"},{"url":"/python_is.html","text":"python is是种很特殊的语法，你在其它的语言应该不会见到这样的用法. python is主要是判断2个变量是否引用的是同一个对象，如果是的话，则返回True，否则返回False 比如: 1 2 a = 'abc' b = 'abc' a is b 返回True,因为变量a和b都存储了字符串'abc'对象的地址。 如果是: 1 2 a = 'abc' c = 'abcd' print a is c 返回False,因为变量a和c存储了字符串对象地址不一致。","tags":"python","title":"Python is的使用"},{"url":"/django_multiple_mysql.html","text":"看了Django的官方文档，关于model这有介绍Multiple databases，但是没有介绍超过两个数据库的连接情况，这里我用mysql举例子，连接3个mysql数据库。估计这么用的不多哈哈哈，我们的需求比较复杂两个mysql上的都是公用数据，然后默认的数据库是我项目使用的数据库，保存着自己项目的账户系统和使用的一些信息。 settings.py 下面是settings文件的配置，添加三个数据库，default为本项目自己的数据库，剩下两个为外部数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 DATABASES = { 'default' : { 'ENGINE' : 'django.db.backends.mysql' , 'NAME' : 'my_db' , 'USER' : 'root' , 'PASSWORD' : '123456' , 'HOST' : '127.0.0.1' , 'PORT' : '3306' , }, 'web_db' : { 'ENGINE' : 'django.db.backends.mysql' , 'NAME' : 'web_db' , 'USER' : 'root' , 'PASSWORD' : '123456' , 'HOST' : '127.0.0.1' , 'PORT' : '3306' , }, 'admin_db' : { 'ENGINE' : 'django.db.backends.mysql' , 'NAME' : 'admin_db' , 'USER' : 'root' , 'PASSWORD' : '123456' , 'HOST' : '127.0.0.1' , 'PORT' : '3306' , }, } router 根据官方文档提示需要自己写个router文件，我的修改如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 class AuthRouter ( object ): \"\"\" 控制 adminapp 应用中模型的 所有数据库操作的路由 \"\"\" def db_for_read ( self , model , ** hints ): if model . _meta . app_label == 'adminapp' : return 'admin_db' elif model . _meta . app_label == 'webapp' : return 'web_db' return None def db_for_write ( self , model , ** hints ): if model . _meta . app_label == 'adminapp' : return 'admin_db' elif model . _meta . app_label == 'qingsong' : return 'web_db' return None def allow_relation ( self , obj1 , obj2 , ** hints ): if obj1 . _meta . app_label == 'adminapp' or obj2 . _meta . app_label == 'adminapp' : return True elif obj1 . _meta . app_label == 'qingsong' or obj2 . _meta . app_label == 'qingsong' : return True return None def allow_syncdb ( self , db , model ): #django1.7 print \"db: %s ,model: %s \" % ( db , model ) print model . _meta . app_label if db == 'admin_db' : return model . _meta . app_label == 'adminapp' elif model . _meta . app_label == 'adminapp' : return False if db == 'qingsong_db' : return model . _meta . app_label == 'qingsong' elif model . _meta . app_label == 'qingsong' : return False return None def allow_migrate ( self , db , model ): #django1.7 if db == 'admin_db' : return model . _meta . app_label == 'adminapp' elif model . _meta . app_label == 'adminapp' : return False return None 然后根据官方文档在settings中加入： 1 DATABASE_ROUTERS = [ 'path.to.AuthRouter' , 'path.to.PrimaryReplicaRouter' ] model中的使用 关于app_label在1.6和1.7中使用稍有不同，官方文档有详细记载，这里我举例Django1.6的方式： 在model中加入app_label标签，这个model属于哪个数据库，写上数据库的名字（settings.py文件中的名字），例如： 1 2 3 4 5 6 7 8 class Test ( models . Model ): name = models . CharField ( max_length = 30 , unique = True ) class Meta : db_table = 'test' app_label = 'adminapp' def __unicode__ ( self ): return self . name","tags":"Django","title":"Django使用两个以上mysql数据库"},{"url":"/talk_work_technology_video.html","text":"今天，谈谈工作，谈谈技术，谈谈理想，谈谈人生 工作 最近，又换了份工作，其实本来是不想走的，但是由于自己太浮躁，换了部门，导致自己没活干，天天混日子也不是我的性格，所以最终确定还是找个靠谱的python业务开发。离职当天，我就高烧39°，战胜病魔后，我痛定思痛，总结了很多，在这里跟大家分享一下。 首先，自己好胜心太强，以至于太急躁，没活干的时候总是胡思乱想，导致了自己换部门，以后在没活干的时候正好是自己积累和学习的过程是个很难得的机会，要好好把握。所以不管干什么要谋定而后动。 其次，要找到自己工作的目标，有了目标就不会胡乱去想。 最后，把目标转化成自己要学的技术，比如我要学的技术就是linux和c，相关的书籍《unix环境编程》《unix网络编程》《unix编程艺术》《c语言程序设计》 关于python开发实践视频 1 初识Python:人人都爱列表 2 共享你的代码：函数模块 3 文件与异常：处理错误 4 持久存储：数据保存到文件 5 推导数据：处理数据！ 6 定制数据对象：打包代码与数据 6课，一共12课时，我答应大家的一定会去录制，最近灿哥正好组织培训分享，我也会加入进去。2个多月没更新视频，一是自己这段时间总是在考虑工作的事，二是在想用什么更好的方式传播分享知识，其实文字是最好的方式，但是文字有时候又不太好表达，自己的文字功底还没练到家。所以我也会尝试的去做一做，基础课程录制完成，稍微的写下gitbook。当做日后实战的教材也好。基础的课程我就不在写太多文字的东西了，因为我是以head first python 为基础录制的，希望大家可以支持他们一下。 这几年一直在琢磨培训学习的事，也是业余培训讲师，随着年岁的增长如果自己发现了更好的学习方法和方式，也会再跟大家分享，弄不好会自己写一本编程的基础书籍。","tags":"随笔","title":"谈工作谈技术谈视频"},{"url":"/sublime_coffeescript_compass_sass.html","text":"没啥难的看我的节奏： 使用Shift + command + P调出命令面板： 输入 install 调出 Package Control: Install Package 选项，按下回车 在列表中分别找到 CoffeeScript，compass，sass和sass build按下回车进行安装 重启Sublime Text 2使之生效","tags":"sublime","title":"sublime 支持开发 coffeescript compass sass"},{"url":"/python_viode_3.html","text":"共享你的代码 共享你的代码课程知识点： 编辑器 注释 命名空间 PyPi 上传 上传PyPi没有成功，因为nester这个模块名已经有了，大家可以更改下名字，再上传测试，这个作为作业。 测试完成 你就可以使用如下命令安装： 1 pip install nester #nester为你自己的模块名 关于编辑器 可以看 配置sublime打造python编辑器 先可以有了自己的需求感觉不方便可参考配置。 Your browser does not support the video tag.","tags":"python开发实践","title":"python开发实践(三)"},{"url":"/python_viode_2.html","text":"人人都爱列表，把之前的坑填完，讲了函数和递归， 人人都爱列表课程知识点： if for 函数 递归 课后可看培强同学的笔记，写的非常棒，整理的比我好： 培强的笔记 配置sublime打造python编辑器 Your browser does not support the video tag.","tags":"python开发实践","title":"python开发实践(二)"},{"url":"/Django_Console_logging_to_STDOUT-.html","text":"最近项目传到服务器上测试，由于没开启log，有些错误没法判断，顾设置之，有此博文。 修改settings文件，添加如下代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 LOGGING = { 'version' : 1, 'disable_existing_loggers' : False, 'formatters' : { 'verbose' : { 'format' : '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s' } , 'simple' : { 'format' : '%(levelname)s %(message)s' } , } , 'handlers' : { 'null' : { 'level' : 'DEBUG' , 'class' : 'logging.NullHandler' , } , 'console' : { 'level' : 'DEBUG' , 'class' : 'logging.StreamHandler' , 'formatter' : 'verbose' , } , 'mail_admins' : { 'level' : 'ERROR' , 'class' : 'django.utils.log.AdminEmailHandler' , # 'filters': ['special'] } } , 'loggers' : { 'django' : { 'handlers' : [ 'console' ] , 'propagate' : True, 'level' : 'ERROR' , } , 'django.request' : { 'handlers' : [ 'mail_admins' ] , 'level' : 'ERROR' , 'propagate' : True, } , } }","tags":"Django","title":"Django错误日志在命令行显示"},{"url":"/sublime_python.html","text":"昨晚长夜漫漫，无心睡眠，运维开发群里交谈不断，突然一位常用vim的同学想开速的学习下sublime的配置，来开发python，由于本人一直使用sublime开发python web项目，索性把自己的配置过程写下来，方便大家交流。 首先，安装上sublime这个就不多说了，本人使用的是宿便sublime Text2 虽然出3了，但是有些插件还没有支持索性不用3。 进入下面的配置文件： Preferences ——》Settings - Default 找到对应的关键字，修改成下面的值，切忌：不是复制下面粘贴进去。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"auto_indent\" : true , \"drag_text\" : false , \"font_face\" : \"\" , \"font_size\" : 17.5, \"ignored_packages\" : [ \"Vintage\" ] , \"tab_size\" : 4, \"translate_tabs_to_spaces\" : true , \"trim_automatic_white_space\" : true , \"word_wrap\" : true } 插件 Package Control 包管理器是必备的，新下载的Sublime Text第一个装的肯定是这个，有了它，装其他的包就很方便了。 适用于 Sublime Text 3： 1、通过快捷键 ctrl+` 或者 View > Show Console 菜单打开控制台 2、粘贴对应版本的代码后回车安装 1 import urllib.request,os ; pf = 'Package Control.sublime-package' ; ipp = sublime.installed_packages_path () ; urllib.request.install_opener ( urllib.request.build_opener ( urllib.request.ProxyHandler ())) ; open ( os.path.join ( ipp,pf ) , 'wb' ) .write ( urllib.request.urlopen ( 'http://sublime.wbond.net/' +pf.replace ( ' ' , '%20' )) .read ()) 适用于 Sublime Text 2： 安装方式有两种，第一种是在线下载安装：在 Sublime Text 2 中按下 \"ctrl+`\"（就是大键盘数字1左边的那个键），拷贝以下命令到窗口下部的终端中， 1 import urllib2,os ; pf = 'Package Control.sublime-package' ; ipp = sublime.installed_packages_path () ; os.makedirs ( ipp ) if not os.path.exists ( ipp ) else None ; urllib2.install_opener ( urllib2.build_opener ( urllib2.ProxyHandler ())) ; open ( os.path.join ( ipp,pf ) , 'wb' ) .write ( urllib2.urlopen ( 'http://sublime.wbond.net/' +pf.replace ( ' ' , '%20' )) .read ()) ; print 'Please restart Sublime Text to finish installation' 然后回车确认，安装完毕之后重启sublime，如果发现在Perferences中看到package control这一项，则安装成功。 然后就可以通过\"command+Shift+P\"打开命令面板，输入\"install\"命令，选择\"Package Control: Install Package\"，然后输入要安装的包的名称，就可以在线安装了。 SublimeCodeIntel插件 智能提示插件，这个插件的智能提示功能非常强大，可以自定义提示的内容库 Preferences ——》Package Settings ——》SublimeCodeIntel ——》Settings - Default 修改里面python的配置，如下： 1 2 3 4 5 6 7 8 \"codeintel_config\" : { \"Python\" : { \"PATH\" : \"usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin: $PATH \" , \"pythonExtraPaths\" : [ \"/usr/local/lib/python2.7/site-packages\" ] , \"python\" : \"/usr/bin/python2.7\" , \"PYTHONPATH\" : \"/usr/local/lib/python2.7/site-packages:/System/Library/Frameworks/Python.framework/Versions/2.7/:/Users/ce/workspace: $PYTHONPATH \" } , } 安装pep8和pylint 实现代码风格和错误检查 sudo pip install pylint sudo pip install pep8 SublimeLinter 这是用来在写代码时做代码检查的。可以在包管理器中安装。写Python程序的话，它还会帮你查代码是否符合PEP8的要求。有问题有代码会出现白框，点击时底下的状态栏会提示出什么问题。 Python PEP8 Autoformat 这是用来按PEP8自动格式化代码的。可以在包管理器中安装。如果以前写程序不留意的话，用SublimeLinter一查，满屏都是白框框，只要装上这个包，按ctrl+shift+r，代码就会按PEP8要求自动格式化了，一屏的白框几乎都消失了 GitGutter 它基于git查看代码行是被增加，修改还是删除，在行数的前面显示如下： SideBarEnhancements 可以大大加强在侧栏目录树中右键的选项 快捷键 1 2 3 4 5 command + p //快速查找特定文件 command + shift + f //多文件搜素 command + r //查看文件内块列表（如果是类文件，展示的是函数） command + alt + num //多屏查看文件 command + k + b //切换左侧目录面板","tags":"python","title":"配置sublime打造python编辑器"},{"url":"/python_viode_1.html","text":"今天更新了python开发实践的第一课，人人都爱列表（一），由于事件匆忙，录制水平没达到理想效果，请大家见谅。第一课还是比较简单的。在这里补充一下大家需要巩固的知识。 首先大家要先有个类UNIX的开发环境，用windows的用户建议安装虚拟机，然后安装pyenv来管理python版本也能达到virtualenv不污染系统环境的功能，接着我们平时调试的时候会用到交互环境默认的不是特别好用，这里推荐使用ipython，安装好后，来跟我一起愉快的玩耍吧。 pyenv安装 ipython安装 Your browser does not support the video tag.","tags":"python开发实践","title":"python开发实践(一)"},{"url":"/python_viode_0.html","text":"python现在变得越来越流行，所以有更多朋友想学习python，有些朋友没有编程基础，买了书看不进去不知道如何下手，报了培训班，讲师良莠不齐，又怕被坑，所以很困惑。许多人来找我交流，所以我就录制一套快速入门的迭代学习方法，让大家快速的学习，把精力用在大家喜爱的项目上。","tags":"python开发实践","title":"python视频动员"},{"url":"/Django_shell.html","text":"最近服务器在线上做测试，没用supervisord管理，有时候必须需要手动来回切换，dev和test启动的方式也不同，索性用shell写个比较low的脚本搞定事情。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash case $1 in dev ) . ~/py2/bin/activate #使用 virtualenv python manage.py runserver store.dev.service.cmos.net:8080 ;; test ) . ~/py2/bin/activate python manage.py runserver store.test.service.cmos.net:8080 ;; * ) echo \"Usage: $0 [dev|test]\" exit 1 ;; esac exit 0","tags":"Django","title":"Django启动shell脚本"},{"url":"/install_ipython.html","text":"今天看到有朋友在用ipython，我也好久没用了，索性装一下 环境为MacOS Python 2.7.5 1 pip install readline ipython 安装完成，输入ipython进入：","tags":"python","title":"安装ipython"},{"url":"/Git-matching-simple.html","text":"如果你最近更新了 Git，你可能会在执行 git push 时看到如下消息： 1 2 3 4 5 6 7 8 9 10 11 12 13 warning: push.default is unset ; its implicit value is changing in Git 2.0 from 'matching' to 'simple' . To squelch this message and maintain the current behavior after the default changes, use: git config --global push.default matching To squelch this message and adopt the new behavior now, use: git config --global push.default simple Matching ‘matching' 参数是 Git 1.x 的默认行为，其意是如果你执行 git push 但没有指定分支，它将 push 所有你本地的分支到远程仓库中对应匹配的分支。 Simple 而 Git 2.x 默认的是 simple，意味着执行 git push 没有指定分支时，只有当前分支会被 push 到你使用 git pull 获取的代码。 修改默认设置 从上述消息提示中的解释，我们可以修改全局配置，使之不会每次 push 的时候都进行提示。对于 matching 输入如下命令即可： 1 git config --global push.default matching 而对于 simple ，请输入： 1 git config --global push.default simple","tags":"git","title":"Git push 中的 Matching和Simple"},{"url":"/flask_blog.html","text":"使用virtualenv sudo pip install virtualenv 建议大家都使用python2.7以上版本 安装flask pip install flask","tags":"flask","title":"flask开发实践（一）"},{"url":"/pythonmechanize.html","text":"mechanize是非常合适的模拟浏览器的模块，它的特点主要有： 1 http,https协议等。 2 简单的HTML表单填写。 3 浏览器历史记录和重载。 4 Referer的HTTP头的正确添加（可选）。 5 自动遵守robots.txt的。 6 自动处理HTTP-EQUIV和刷新。 所以你可以用mechanize来完成一些自动化浏览器想要做的事情，比如自动登录表单，自动填写表单等 确保已经安装：pip install mechanize 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/usr/bin/python import mechanize #引入mechanize 需要pip安装 import cookielib #引入cookielib 来做cookie url = 'http://127.0.0.1:8080/login' username = 'zhangbin' password = 'zhangbin' def login (): br = mechanize . Browser () cj = cookielib . LWPCookieJar () br . set_cookiejar ( cj ) #关联cookies #设置一些参数，因为是模拟客户端请求，所以要支持客户端的一些常用功能 br . set_handle_equiv ( True ) br . set_handle_gzip ( True ) br . set_handle_redirect ( True ) br . set_handle_referer ( True ) br . set_handle_robots ( False ) br . set_handle_refresh ( mechanize . _http . HTTPRefreshProcessor (), max_time = 1 ) br . addheaders = [( 'User-agent' , 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.1.11) Gecko/20100701 Firefox/3.5.11' )] #模拟浏览器头 # br.set_debug_http(True) #debug # br.set_debug_responses(True) #debug br . open ( url ) #打开连接 br . select_form ( nr = 0 ) #选择第一个form br . form [ 'email' ] = username #写入用户名 br . form [ 'password' ] = password #写入密码 br . submit () #提交 print br . response () . read () #打印登录后内容 if __name__ == '__main__' : login ()","tags":"python","title":"python使用mechanize实现登陆"},{"url":"/django_password_reset-.html","text":"Django，是个不错的框架，非常全，内置了用户系统，咱们稍微修改就可以实现发送重置密码邮件。 url.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 from django.contrib.auth import views as auth_views urlpatterns = patterns ( '' , url ( r'&#94;forgot-password/$' , views . forgot_password , name = \"forgot-password\" ), url ( r'&#94;password/change/$' , auth_views . password_change , name = 'password_change' ), url ( r'&#94;password/change/done/$' , auth_views . password_change_done , name = 'password_change_done' ), url ( r'&#94;resetpassword/$' , auth_views . password_reset , name = 'password_reset' ), url ( r'&#94;resetpassword/passwordsent/$' , auth_views . password_reset_done , name = 'password_reset_done' ), url ( r'&#94;reset/done/$' , auth_views . password_reset_complete , name = 'password_reset_complete' ), url ( r'&#94;reset/(?P<uidb64>[0-9A-Za-z_\\-]+)/(?P<token>.+)/$' , auth_views . password_reset_confirm , name = 'password_reset_confirm' ), ) templates设置 在 django/contrib/auth/templates/registration 中copy如下文件到自己的templates目录下的registration中： password_reset_subject.txt 在 django/contrib/admin/templates/registration 中copy如下文件到自己的templates目录下的registration中： logged_out.html password_change_done.html password_change_form.html password_reset_complete.html #修改密码完成的文件 password_reset_confirm.html password_reset_done.html password_reset_email.html #发email的文件 password_reset_form.html 可根据自己的需求进行定义我在这里面，就把logged_out.html文件删除了，加入了自己写的login.html，然后将所有文件中的{% extends \"admin/base_site.html\" %} 改为{% extends \"base.html\" %} 这样做完还是不能用的，因为需要base.html文件: 1 2 3 4 5 6 7 8 <html> <head> <title> {% block title %}{% endblock title %} </title> </head> <body> {% block content %}{% endblock content %} </body> </html> 测试 点击忘记密码： 输入自己的邮箱地址。 不一会就会收到邮件： 内容为： 想修改邮件内容可以修改templates/registration/password_reset_email.html文件。","tags":"Django","title":"Django实现发送邮件重置用户密码"},{"url":"/Time_Complexity.html","text":"算法实际那复杂度定义 推导大O阶 1.用常数1取代运行时间中的所有加法常数。 2.在修改后得运行次数函数中，只保留最高阶项 。 3.如果最高阶项存在且不是1，则去除与这个项相乘的常数。 得到的结果就是大O阶 常数阶 1 2 3 int sum = 0 , n = 100 ; /* 执行一次 */ sum = ( 1 + n ) * n / 2 ; /* 执行一次 */ printf ( \"%d\" , sum ); /* 执行一次 */ 这个算法运行次数函数是f(n)=3.根据我们推到大O阶的方法，第一步就是把常数项3改为1。在保留最高阶项时发现，它根本没有最高阶项，所以这个算法的时间复杂度为O(1)。 线性阶 对数阶 平方阶","tags":"算法","title":"算法的时间复杂度"},{"url":"/Django_ajax_post-.html","text":"在web项目中，ajax运用非常频繁，今天就给大家展示下Django ajax Post的使用方法 templates 模板 index.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 <html> <header></header> <body> <p> name: <input type= \"text\" name= \"nickname\" /></p> <input class= \"name_submit\" type= \"submit\" value= \"Submit\" /> <div class= \"name_value\" ></div> </body> <script src= \"/static/js/jquery.js\" ></script> <script type= \"text/javascript\" > $ ( \".name_submit\" ). click ( function (){ var nickname = $ ( \"input[name='nickname']\" ). val (); $ . ajax ({ url : \"/nickname\" , type : \"post\" , data : { \"nickname\" : nickname }, dataType : \"json\" , success : function ( data ){ $ ( \".name_value\" ). text ( \"\" ) $ ( \".name_value\" ). append ( \"名字为:\" + data ) } }); // Ajax End }); </script> </html> 显示如下： 当点击提交按钮时，就执行ajax，把获取的nickname传递到/nickname url中。 url 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.conf.urls import patterns , include , url from django.contrib import admin from views import index , nickname admin . autodiscover () urlpatterns = patterns ( '' , # Examples: url ( r'&#94;$' , index ), url ( r'&#94;nickname$' , nickname ), url ( r'&#94;admin/' , include ( admin . site . urls )), ) 从这里可以看到/nickname URL是views文件中的nickname函数 views 1 2 3 4 5 6 7 8 9 10 11 12 #coding=utf-8 from django.shortcuts import render , render_to_response from django.http import HttpResponseRedirect , HttpResponse from django.template import Template , Context def index ( request ): if request . method == 'GET' : return render_to_response ( \"index.html\" ) def nickname ( request ): if request . method == 'POST' : #当request为POST的时候 nickname = request . POST . get ( 'nickname' , '' ) #获取ajax POST的nickname值 return HttpResponse ( nickname ) #为了方便显示，直接在浏览器显示nickname nickname函数 当时POST的时候，获取nickname值，然后为了方便显示就直接使用return HttpResponse(nickname) 直接展示出来nickname值","tags":"Django","title":"Django ajax post"},{"url":"/python_and_highcharts.html","text":"有时候我们需要制作一些图表，单独使用python可以制作出但是不是特别好看，今天我们就用Django和highcharts神器来做出好看的图标，如想要详细了解highcharts请关注如下网站： highcharts官网 highcharts中文网 前端准备: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 <html> <head></head> <body> <div id= \"container\" style= \"height: 300px\" ></div> </body> <script type= \"text/javascript\" > $ ( function () { $ ( '#container' ). highcharts ({ chart : { type : 'column' }, title : { text : 'ip统计' }, xAxis : { categories : {{ ip_time }} }, //ip_time数据为：[20140501, 20140502, 20140503, 20140504, 20140505] yAxis : { min : 0 , title : { text : 'ip数量 (ip)' } }, plotOptions : { column : { pointPadding : 0.2 , borderWidth : 0 } }, series : [{ name : 'ip' , data : {{ ip_conut }} //ip_conut数据为：[853, 821, 829, 1048, 1014] }] }); }); </script> </html> 后端views实现： 1 2 3 4 5 def ip ( request ): if request . method == 'GET' : ip_time = [ 20140501 , 20140502 , 20140503 , 20140504 , 20140505 ] ip_conut = [ 853 , 821 , 829 , 1048 , 1014 ] return render_to_response ( \"app_detail.html\" , RequestContext ( request , { 'ip_time' : ip_time , 'ip_conut' : ip_conut })) 这里的数据只是个例子，更直观的展示出效果，真正项目中可能需要你在数据库中取出数据，自己折腾成list，我们看下效果：","tags":"python","title":"python和highcharts制作图表"},{"url":"/python_md5-.html","text":"Python中，用于加密的md5方法在hashlib模块中，文件的MD5校验码是根据文件的内容生成的信息摘要，方法如下: 1 2 3 4 5 6 7 8 9 10 11 from hashlib import md5 def md5_file ( name ): m = md5 () a_file = open ( name , 'rb' ) #使用二进制格式读取文件内容 m . update ( a_file . read ()) a_file . close () return m . hexdigest () if __main__ == '__init__' : print md5_file ( '/home/ce/1.txt' )","tags":"python","title":"python计算文件md5"},{"url":"/tornado-session-.html","text":"tornado属于轻量级，异步，高并发的代名词了，虽然开发网站的速度比较慢，但是大多数同学开发后端服务，还都是喜欢使用tornado，今天给大家分享一下，tornado中自己做session时，写装饰器的代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #coding=utf-8 import models from tornado.web import HTTPError def check_login ( func ): def _wrapper ( self , * args , ** kwargs ): session_id = self . request . headers . get ( 'Session_id' , None ) user_id = self . request . headers . get ( 'User_id' , None ) session_data = models . session . query ( models . Session ) . filter_by ( user_id = user_id ) . first () if session_id : ret = func ( self , * args , ** kwargs ) if session_data . session_id == session_id : return ret else : raise HTTPError ( 403 ) else : raise HTTPError ( 403 ) return _wrapper","tags":"tornado","title":"tornado session装饰器"},{"url":"/django.html","text":"最近换了新公司，公司新项目要用Django，因为现在的领导对Django比较熟悉，对于我这种运维出身，对性能有着要求的人不能用tornado这种牛逼框架，心里是无限的悲伤啊。没办法日子还得过啊，所以进入可繁忙的开发期，这一用不要紧，还用出了感情，发现Django还多内置的app搭建网站速度还真快，接下来就给大家介绍一下他的用户系统 Django版本：1.6.2 Django用户系统 Django自带了用户系统，里面包含了认证系统，非常好用，可以免去自己造轮子，但是由于Django内部的用户系统可用字段只有firstname，lastname，email等几个基础的字段，如果要实现有中国特色的好web必须需要进行扩展，经过一段时间的研究，终于搞定。 自定义用户系统 现在自己的项目中建立一个app，也就是一个目录，里面要有 __init__.py 文件 然后根据官方文档的要求创建并写入models.py文件： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 #! /usr/bin/env python #coding=utf-8 from django.db import models from django.contrib.auth.models import ( BaseUserManager , AbstractBaseUser , PermissionsMixin ) class UserManager ( BaseUserManager ): def create_user ( self , email , username , telephone , password = None ): \"\"\" Creates and saves a User with the given email, date of birth and password. \"\"\" if not email : raise ValueError ( 'Users must have an email address' ) user = self . model ( email = self . normalize_email ( email ), username = username , telephone = telephone , ) user . set_password ( password ) user . save ( using = self . _db ) return user def create_superuser ( self , email , username , password , telephone = \"\" ): \"\"\" Creates and saves a superuser with the given email, username and password. \"\"\" user = self . create_user ( email = email , username = username , password = password , telephone = telephone ) user . is_admin = True user . save ( using = self . _db ) return user class User ( AbstractBaseUser , PermissionsMixin ): #注意：不继承PermissionsMixin类，是无法实现使用Django Group功能的，本人的项目需要使用所以继承该类。 email = models . EmailField ( verbose_name = 'email address' , max_length = 255 , unique = True , ) username = models . CharField ( max_length = 100 , unique = True , db_index = True ) # avatar = models.URLField( # blank=True # ) telephone = models . CharField ( max_length = 50 ) created_at = models . DateTimeField ( auto_now_add = True ) is_active = models . BooleanField ( default = True ) is_admin = models . BooleanField ( default = False ) objects = UserManager () USERNAME_FIELD = 'email' REQUIRED_FIELDS = [ 'username' ] def get_full_name ( self ): # The user is identified by their email address return self . email def get_short_name ( self ): # The user is identified by their email address return self . username # On Python 3: def __str__(self): def __unicode__ ( self ): return self . email def has_perm ( self , perm , obj = None ): \"Does the user have a specific permission?\" # Simplest possible answer: Yes, always return True def has_module_perms ( self , app_label ): \"Does the user have permissions to view the app `app_label`?\" # Simplest possible answer: Yes, always return True @property def is_staff ( self ): \"Is the user a member of staff?\" # Simplest possible answer: All admins are staff return self . is_admin 然后，我们要注册admin，再创建admin.py文件： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 from django import forms from django.contrib import admin from django.contrib.auth.models import Group from django.contrib.auth.admin import UserAdmin from django.contrib.auth.forms import ReadOnlyPasswordHashField from app_store.account.models import User class UserCreationForm ( forms . ModelForm ): \"\"\"A form for creating new users. Includes all the required fields, plus a repeated password.\"\"\" password1 = forms . CharField ( label = 'Password' , widget = forms . PasswordInput ) password2 = forms . CharField ( label = 'Password confirmation' , widget = forms . PasswordInput ) class Meta : model = User fields = ( 'email' , 'username' , 'telephone' ) def clean_password2 ( self ): # Check that the two password entries match password1 = self . cleaned_data . get ( \"password1\" ) password2 = self . cleaned_data . get ( \"password2\" ) if password1 and password2 and password1 != password2 : raise forms . ValidationError ( \"Passwords don't match\" ) return password2 def save ( self , commit = True ): # Save the provided password in hashed format user = super ( UserCreationForm , self ) . save ( commit = False ) user . set_password ( self . cleaned_data [ \"password1\" ]) if commit : user . save () return user class UserChangeForm ( forms . ModelForm ): \"\"\"A form for updating users. Includes all the fields on the user, but replaces the password field with admin's password hash display field. \"\"\" password = ReadOnlyPasswordHashField () class Meta : model = User fields = ( 'email' , 'password' , 'username' , 'telephone' , 'is_active' , 'is_admin' ) def clean_password ( self ): # Regardless of what the user provides, return the initial value. # This is done here, rather than on the field, because the # field does not have access to the initial value return self . initial [ \"password\" ] class UserAdmin ( UserAdmin ): # The forms to add and change user instances form = UserChangeForm add_form = UserCreationForm # The fields to be used in displaying the User model. # These override the definitions on the base UserAdmin # that reference specific fields on auth.User. list_display = ( 'email' , 'username' , 'is_admin' ) list_filter = ( 'is_admin' , 'groups' ) fieldsets = ( ( None , { 'fields' : ( 'email' , 'password' )}), ( 'Personal info' , { 'fields' : ( 'username' , 'groups' )}), ( 'Permissions' , { 'fields' : ( 'is_admin' ,)}), ) # add_fieldsets is not a standard ModelAdmin attribute. UserAdmin # overrides get_fieldsets to use this attribute when creating a user. add_fieldsets = ( ( None , { 'classes' : ( 'wide' ,), 'fields' : ( 'email' , 'username' , 'password1' , 'password2' )} ), ) search_fields = ( 'email' ,) ordering = ( 'email' ,) filter_horizontal = () # Now register the new UserAdmin... admin . site . register ( User , UserAdmin ) # ... and, since we're not using Django's built-in permissions, # unregister the Group model from admin. # admin.site.unregister(Group) # admin.site.register(Group) 关于admin.site.unregister(Group)，官方写的是不注册到admin，但是根据我自己的需求，我还是需要Group功能来做权限的，所以就注释掉了该行。 然后要将写好的 account 加入到settings文件的INSTALLED_APPS中，如下： 1 2 3 4 5 6 7 8 9 10 INSTALLED_APPS = ( 'django.contrib.admin' , 'django.contrib.auth' , 'django.contrib.contenttypes' , 'django.contrib.sessions' , 'django.contrib.messages' , 'django.contrib.staticfiles' , 'test' , #自己的应用 'test.account' , #建立的account应用 ) 然后设置在settings文件中加入： 1 AUTH_USER_MODEL = 'account.User' 接着同步数据库： 1 python manager.py sync 应用 在view中直接写注册方法，如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.shortcuts import render_to_response from django.http import HttpResponse from app_store.account.models import User def register ( request ): if request . method == 'GET' : return render_to_response ( \"register.html\" ) if request . method == 'POST' : username = request . POST [ 'username' ] password = request . POST [ 'password' ] email = request . POST [ 'email' ] telephone = request . POST [ 'telephone' ] User . objects . create_user ( email = email , username = username , password = password , telephone = telephone ) html = '''<html><head><body><a href=\"/\">回到首页</a><h2>注册成功</h2></body></head></html>''' return HttpResponse ( html )","tags":"django","title":"Django自定义用户系统"},{"url":"/pythonshi-xian-kong-zhi-mplayer.html","text":"今天有这么一个需求，让用python来控制MPlayer，实现一个简单的web，功能有：暂停，播放，快进，快退，显示播放list，进度，显示当前播放文件名等等，本着不重复造轮子的理念，在Google一搜，发现了 mplayer.py 这个神器，来马上试用一下。 Mplayer安装 我都用的是Mac系统（怎么这么不低调呢，这毛病什么时候能改），安装了MplayerX一到命令行输入：mplayer命令发现没命令，我就慌了，职业病的拿起brew进行安装： 1 brew install mplayer 没想到还真提示有包，安装ing。 当然，Ubuntu也不能少： apt-get install mplayer 应该不会发生什么太大问题 mplayer.py 安装 1 pip install mplayer.py 还是非常的方便 测试 进入python命令行，我们来测试： (env)ce@mac:~> python Python 2.7.5 (default, Aug 25 2013, 00:04:04) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> >>> from mplayer import Player, CmdPrefix 根据文档，先引入需要的函数 >>> Player.cmd_prefix = CmdPrefix.PAUSING_KEEP 设置默认前缀为所有player的实例 >>> player = Player() 建立实例 >>> player.loadfile('/path/to/file.mkv') 引入文件，引入后文件就被打开了 这时候我们可以dir player来看看他都有什么方法让我们使用 >>> dir(player) ['__class__', '__del__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_args', '_base_args', '_gen_method_func', '_gen_propdoc', '_generate_methods', '_generate_properties', '_proc', '_process_args', '_propget', '_propset', '_run_command', '_stderr', '_stdout', 'af_add', 'af_clr', 'af_cmdline', 'af_del', 'af_switch', 'alt_src_step', 'angle', 'args', 'aspect', 'ass_use_margins', 'audio_bitrate', 'audio_codec', 'audio_delay', 'audio_format', 'balance', 'border', 'brightness', 'capturing', 'change_rectangle', 'channels', 'chapter', 'chapters', 'cmd_prefix', 'contrast', 'deinterlace', 'demuxer', 'dvdnav', 'edl_loadfile', 'edl_mark', 'exec_path', 'exit', 'file_filter', 'filename', 'forced_subs_only', 'fps', 'frame_drop', 'frame_step', 'framedropping', 'fullscreen', 'gamma', 'gui', 'height', 'help', 'hide', 'hue', 'introspect', 'is_alive', 'key_down_event', 'length', 'loadfile', 'loadlist', 'loop', 'menu', 'metadata', 'mute', 'ontop', 'osd', 'osd_show_progression', 'osd_show_property_text', 'osd_show_text', 'osdlevel', 'overlay_add', 'overlay_remove', 'panscan', 'path', 'pause', 'paused', 'percent_pos', 'pt_step', 'pt_up_step', 'quit', 'rootwin', 'run', 'samplerate', 'saturation', 'screenshot', 'seek', 'seek_chapter', 'set_menu', 'set_mouse_pos', 'spawn', 'speed', 'speed_incr', 'speed_mult', 'speed_set', 'stderr', 'stdout', 'stop', 'stream_end', 'stream_length', 'stream_pos', 'stream_start', 'stream_time_pos', 'sub', 'sub_alignment', 'sub_delay', 'sub_demux', 'sub_file', 'sub_forced_only', 'sub_load', 'sub_log', 'sub_pos', 'sub_remove', 'sub_scale', 'sub_select', 'sub_source', 'sub_step', 'sub_visibility', 'sub_vob', 'switch_angle', 'switch_audio', 'switch_program', 'switch_ratio', 'switch_title', 'switch_video', 'switch_vsync', 'teletext_add_dec', 'teletext_format', 'teletext_go_link', 'teletext_half_page', 'teletext_mode', 'teletext_page', 'teletext_subpage', 'time_pos', 'titles', 'tv_brightness', 'tv_contrast', 'tv_hue', 'tv_last_channel', 'tv_saturation', 'tv_set_brightness', 'tv_set_channel', 'tv_set_contrast', 'tv_set_freq', 'tv_set_hue', 'tv_set_norm', 'tv_set_saturation', 'tv_start_scan', 'tv_step_chanlist', 'tv_step_channel', 'tv_step_freq', 'tv_step_norm', 'use_master', 'version', 'video_bitrate', 'video_codec', 'video_format', 'vo_border', 'vo_fullscreen', 'vo_ontop', 'vo_rootwin', 'vobsub_lang', 'volume', 'vsync', 'width'] very well！ 看来我们的需求是可以搞定了！ 需要的方法 下面罗列下需要使用的方法： player.pause() #暂停 player.filename #显示文件名 player.time_pos += 5 #快进5s player.time_pos -= 5 #快退5s player.stream_length #查看视频长度 player.stream_pos #查看视频现在的位置， 根据上面可以做出进度条 player.volume #显示音量 player.volume(+30.0) #升高音量 player.volume(-30.0) #降低音量 player.quit() #关闭视频 好ok，有了以上功能大家是不是就已经可以控制Mplayer拉？现在就只差web界面了。","tags":"python","title":"python实现控制Mplayer"},{"url":"/pythonshi-xian-fen-xi-nginxri-zhi-webping-tai.html","text":"其实项目写完好久了，一直没时间总结，正好最近离职，也不是特别忙把一些自己认为使用的项目分享一下给大家，希望能帮助到大家，即使帮助不到，我还可以偷偷回来看下，以便温习 Nginx日志 按日期切割log 1 2 3 mv / var / log / nginx - server . access . log / var / log / nginx / nginx - server . access_ $ ( date - d \"yesterday\" + \"%Y%m% d \").log kill - USR1 `cat /etc/nginx/logs/nginx.pid` 首先要明确自己的Nginx的日志格式，找到配置文件如下： 1 2 3 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$request_time\" \"$upstream_response_time\"' ; 以上是我Nginx日志的格式 Nginx日志分析处理 啥也别说了 直接上代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 #coding=utf-8 import linecache import re import time , datetime import glob import os import conn w = '''112.224.65.85 - - [20/Aug/2013:00:01:02 +0800] \"POST /api/topic/comments HTTP/1.1\" 200 3804 \"-\" \"Corax/0.7.0 CFNetwork/609.1.4 Darwin/13.0.0\" \"-\" \"1.173\" \"0.005\"''' files_dir = \"/home/corax/ops/data/\" bak_dir = \"/home/corax/ops/data/backup\" def readfile ( path ): filename = [] files = glob . glob ( path + '*.log' ) return files def readtime ( path ): read_time = [] files = glob . glob ( path + '*.log' ) print files for i in files : read_time . append ( i . split ( '_' )[ 1 ] . split ( '.' )[ 0 ]) read_time = set ( read_time ) return read_time def timestamp ( time_file ): return time . mktime ( time . strptime ( time_file , '%Y%b %d %H:%M:%S' )) def datestamp ( date_name ): return time . strptime ( date_name , '%Y%b %d ' ) def handle_log ( log_file ): ip = r\"?P<ip>[\\d.]*\" date = r\"?P<date>\\d+\" month = r\"?P<month>\\w+\" year = r\"?P<year>\\d+\" log_time = r\"?P<time>\\S+\" method = r\"?P<method>\\S+\" request = r\"?P<request>\\S+\" status = r\"?P<status>\\d+\" bodyBytesSent = r\"?P<bodyBytesSent>\\d+\" refer = r\"\"\"?P<refer> [&#94;\\\"]* \"\"\" userAgent = r\"\"\"?P<userAgent> \\S* \"\"\" forwardr = r\"\"\"?P<forwardr> [&#94;\\\"]* \"\"\" request_time = r\"\"\"?P<request_time> [&#94;\\\"]* \"\"\" response_time = r\"\"\"?P<response_time> [&#94;\\\"]* \"\"\" p = re . compile ( r\"( %s )\\ -\\ -\\ \\[( %s )/( %s )/( %s )\\:( %s )\\ [\\S]+\\]\\ \\\" ( %s )?[\\s]?( %s )?.*? \\\" \\ ( %s )\\ ( %s )\\ \\\" ( %s ) \\\" \\ \\\" ( %s ).*? \\\" \\ \\\" ( %s ) \\\" \\ \\\" ( %s ) \\\" \\ \\\" ( %s ) \\\" \" % ( ip , date , month , year , log_time , method , request , status , bodyBytesSent , refer , userAgent , forwardr , request_time , response_time ), re . VERBOSE ) s = time . time () log_list = [] for l in log_file : f = open ( l , 'r' ) file_all = f . read () m = re . findall ( p , file_all ) for g in m : time_all = ' %s%s%s %s ' % ( g [ 3 ], g [ 2 ], g [ 1 ], g [ 4 ]) time_format = timestamp ( time_all ) date = time . strftime ( \"%Y%m %d \" , datestamp ( ' %s%s%s ' % ( g [ 3 ], g [ 2 ], g [ 1 ]))) hour = g [ 4 ] . split ( \":\" )[ 0 ] # print date,hour if g [ 12 ] != \"-\" : req_time = float ( g [ 12 ]) else : req_time = None if g [ 13 ] != \"-\" and len ( g [ 13 ]) <= 5 : res_time = float ( g [ 13 ]) else : res_time = None log = { 'ip' : g [ 0 ], 'time' : time_format , 'method' : g [ 5 ], 'request' : g [ 6 ], 'status' : g [ 7 ], 'bodyBytesSent' : g [ 8 ], 'refer' : g [ 9 ], 'userAgent' : g [ 10 ], 'forwardr' : g [ 11 ], 'request_time' : req_time , 'response_time' : res_time , 'date' : int ( date ), 'hour' : int ( hour )} conn . db . log . insert ( log ) f . close () print \"mv %s %s \" % ( l , bak_dir ) os . system ( \"mv %s %s \" % ( l , bak_dir )) print time . time () - s if __name__ == '__main__' : lf = readfile ( files_dir ) print lf read_time = readtime ( files_dir ) print read_time handle_log ( lf ) 我们书接上回，对上面的代码进行一下梳理： w变量存了一个测试的Nginx日志条目,readfile()函数是读取日志文件，然后返回文件的路径，readtime()函数是获取日期，handle_log()函数是分析日志的函数，对于每个日志段，用正则精心匹配筛选出来，然后就是入库。这里面试写入到了MongDB中。 好了，日志都放到NOSQL当中了，接下来就是分析的问题，这个就是仁者见仁智者见智的事了，每个公司的需求不一样，有用redis分析的，有用zeromq分析，这就看大家的喜好了，分析完最后还是推荐大家用highcharts出图比较好看，这里推荐使用highcharts的文章： highcharts使用","tags":"python","title":"python实现分析Nginx日志web平台"},{"url":"/sqlalchemycha-xun-fan-hui-jsonshu-ju.html","text":"最近公司开发新项目使用tornado+mysql，传统的SQL开发方式大家都感觉不爽（其实我不太会，哈哈），所以开始使用orm方式，这也是python社区大家所推崇的方式，技术选型就选择了霸道的神器 sqlalchemy 返回json数据 使用tornado做apps的服务端，很多时候需要返回json数据，但是sqlalchemy默认没提供这种方法，所以经过今天查询网上的资料自己实现了一个方法。 为了在tornado中增加json支持，需要在model（默认tornado是没有model的，使用sqlalchemy，大家一般会写个models.py文件来做model）里面增加__json__方法： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #coding=utf-8 import json from sqlalchemy import create_engine , DDL , event from sqlalchemy.orm import sessionmaker from sqlalchemy import Column , Integer , String , Date , Boolean , Unicode from sqlalchemy.ext.declarative import declarative_base from settings import mysql_passwd DB_CONNECT_STRING = 'mysql+mysqlconnector://root: %s @localhost:3306/test?charset=utf8' % mysql_passwd engine = create_engine ( DB_CONNECT_STRING , echo = False ) DB_Session = sessionmaker ( bind = engine ) session = DB_Session () Base = declarative_base () #给Base添加__json__方法 使输出JSON数据 def sqlalchemy_json ( self ): obj_dict = self . __dict__ return dict (( key , obj_dict [ key ]) for key in obj_dict if not key . startswith ( \"_\" )) Base . __json__ = sqlalchemy_json 这样搞定以后在你的程序想要调用model的时候如下使用就会输出json数据： 1 2 3 4 5 class users ( BaseHandler ): def get ( self ): user_id = self . get_argument ( \"user_id\" ) #获取user_id user_info = self . session . query ( models . User ) . filter_by ( id = user_id ) . first () #查询user信息 self . write ( json . dumps ({ \"status\" : 0 , \"msg\" : \"返回成功\" , \"user_info\" : models . User . __json__ ( user )}, ensure_ascii = False , indent = 4 )) #返回自定义数据，models.User.__json__(user)就是使用在Base创建的__json__方法来返回json数据，ensure_ascii=False是不使用ascii为了显示中文，indent=4是缩进，格式化输出json比较美观","tags":"sqlalchemy","title":"sqlalchemy查询返回json数据"},{"url":"/http-header-xiang-jie.html","text":"HTTP（HyperTextTransferProtocol）即超文本传输协议，目前网页传输的的通用协议。HTTP协议采用了请求/响应模型，浏览器或其他客户端发出请求，服务器给与响应。就整个网络资源传输而言，包括message-header和message-body两部分。首先传递message- header，即http header消息 。http header 消息通常被分为4个部分：general header, request header, response header, entity header。但是这种分法就理解而言，感觉界限不太明确。根据维基百科对http header内容的组织形式，大体分为Request和Response两部分。 Requests部分 Header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集 Accept-Charset: iso-8859-5 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接。（HTTP 1.1默认进行持久连接） Connection: close CookieHTTP 请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 Cookie: $Version=1; Skin=new; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 Host: www.zcmhi.com If-Match 只有请求内容与实体相匹配才有效 If-Match: \"737060cd8c284d8af7ad3082f209582d\" If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: \"737060cd8c284d8af7ad3082f209582d\" If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: \"737060cd8c284d8af7ad3082f209582d\" If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后,即来路 Referer: http://www.zcmhi.com/archives/71.html TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent User-Agent的内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 (Linux; X11) Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning Responses 部分 Header 解释 示例 test test test","tags":"HTTP","title":"HTTP Header 详解"},{"url":"/pythonzhong-de-urlencodeyu-urldecode.html","text":"转载： 地址 . 概要：python 通过 HTTP 交互处理数据的时候，url 里面的中文以及特殊字符要做处理的，来学习一下 urlencode 与 urldecode 之间相互转换的方法。 当url地址含有中文，或者参数有中文的时候，这个算是很正常了，但是把这样的url作为参数传递的时候（最常见的callback），需要把一些中文甚至'/'做一下编码转换。 一、urlencode urllib库里面有个urlencode函数，可以把key-value这样的键值对转换成我们想要的格式，返回的是a=1&b=2这样的字符串，比如: >>> from urllib import urlencode >>> data = { ... 'a': 'test', ... 'name': '魔兽' ... } >>> print urlencode(data) a=test&amp;name=%C4%A7%CA%DE 如果只想对一个字符串进行urlencode转换，怎么办？urllib提供另外一个函数：quote() >>> from urllib import quote >>> quote('魔兽') '%C4%A7%CA%DE' 二、urldecode 当urlencode之后的字符串传递过来之后，接受完毕就要解码了——urldecode。urllib提供了unquote()这个函数，可没有urldecode()！: >>> from urllib import unquote >>> unquote('%C4%A7%CA%DE') '\\xc4\\xa7\\xca\\xde' >>> print unquote('%C4%A7%CA%DE') 魔兽 三、讨论 在做urldecode的时候，看unquote()这个函数的输出，是对应中文在gbk下的编码，在对比一下quote()的结果不难发现，所谓的urlencode就是把字符串转车gbk编码，然后把\\x替换成%。如果你的终端是utf8编码的，那么要把结果再转成utf8输出，否则就乱码。 可以根据实际情况，自定义或者重写urlencode()、urldecode()等函数。","tags":"python","title":"python中的urlencode与urldecode"},{"url":"/nginxda-zao-3wgao-bing-fa-wang-zhan.html","text":"Nginx是俄罗斯人编写的十分轻量级的HTTP服务器,Nginx，它的发音为\"engine X\"，是一个高性能的HTTP和反向代理服务器，同时也是一个IMAP/POP3/SMTP 代理服务器．Nginx是由俄罗斯人 Igor Sysoev为俄罗斯访问量第二的 Rambler.ru站点开发. Nginx以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配 Lighttpd的性能，同时还没有Lighttpd的内存泄漏问题，而且Lighttpd的mod_proxy也有一些问题并且很久没有更新。但是Nginx并不支持cgi方式运行，原因是可以减少因此带来的一些程序上的漏洞。所以必须使用FastCGI方式来执行PHP程序。 nginx做为HTTP服务器，有以下几项基本特性： 处理静态文件，索引文件以及自动索引；打开文件描述符缓冲． 无缓存的反向代理加速，简单的负载均衡和容错． FastCGI，简单的负载均衡和容错． 模块化的结构。包括gzipping, byte ranges, chunked responses,以及 SSI-filter等filter。如果由FastCGI或其它代理服务器处理单页中存在的多个SSI，则这项处理可以并行运行，而不需要相互等待。 Nginx专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率。它支持内核Poll模型，能经受高负载的考验,有报告表明能支持高达 50,000个并发连接数。 Nginx具有很高的稳定性。其它HTTP服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前apache一旦上到200个以上进程，web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术，使得它的CPU与内存占用率非常低。nginx官方表示保持10,000个没有活动的连接，它只占2.5M内存，所以类似DOS这样的攻击对nginx来说基本上是毫无用处的。就稳定性而言,nginx比lighthttpd更胜一筹。 Nginx支持热部署。它的启动特别容易, 并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在不间断服务的情况下，对软件版本进行进行升级。 编译安装过程优化 在编译Nginx时，默认以debug模式进行，而在debug模式下会插入很多跟踪和ASSERT之类的信息，编译完成后，一个Nginx要有好几兆字节。在编译前取消Nginx的debug模式，编译完成后Nginx只有几百千字节，因此可以在编译之前，修改相关源码，取消debug模式，具体方法如下： 在Nginx源码文件被解压后，找到源码目录下的auto/cc/gcc文件，在其中找到如下几行: # debug CFLAGS=\"$CFLAGS -g\" 为特定的CPU指定CPU类型编译优化 在编译Nginx时，默认的GCC编译参数是\"-O\"，要优化GCC编译，可以使用以下两个参数: --with-cc-opt='-O3' --with-cpu-opt=CPU #为特定的 CPU 编译，有效的值包括：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, amd64, sparc32, sparc64, ppc64 要确定CPU类型，可以通过如下命令: [root@localhost home]#cat /proc/cpuinfo | grep \"model name\" 利用TCMalloc优化Nginx的性能 TCMalloc的全称为Thread-Caching Malloc，是谷歌开发的开源工具\"google-perftools\"中的一个成员。与标准的glibc库的malloc相比，TCMalloc库在内存分配效率和速度上要高很多，这在很大程度上提高了服务器在高并发情况下的性能，从而降低系统负载。下面简单介绍如何为Nginx添加TCMalloc库支持。 要安装TCMalloc库，需要安装libunwind（32位操作系统不需要安装）和google-perftools两个软件包，libunwind库为基于64位CPU和操作系统的程序提供了基本函数调用链和函数调用寄存器功能。下面介绍利用TCMalloc优化Nginx的具体操作过程： 1.安装libunwind库 可以从http://download.savannah.gnu.org/releases/libunwind下载相应的libunwind版本，这里下载的是libunwind-0.99-alpha.tar.gz，安装过程如下 [root@localhost home]#tar zxvf libunwind-0.99-alpha.tar.gz [root@localhost home]# cd libunwind-0.99-alpha/ [root@localhost libunwind-0.99-alpha]#CFLAGS=-fPIC ./configure [root@localhost libunwind-0.99-alpha]#make CFLAGS=-fPIC [root@localhost libunwind-0.99-alpha]#make CFLAGS=-fPIC install 2.安装google-perftools 可以从http://google-perftools.googlecode.com下载相应的google-perftools版本，这里下载的是google-perftools-1.8.tar.gz，安装过程如下: [root@localhost home]# tar zxvf google-perftools-1.8.tar.gz [root@localhost home]# cd google-perftools-1.8/ [root@localhost google-perftools-1.8]# ./configure [root@localhost google-perftools-1.8]# make && make install [root@localhost google-perftools-1.8]# echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf [root@localhost google-perftools-1.8]# ldconfig 至此，google-perftools安装完成。 3.重新编译Nginx 为了使Nginx支持google-perftools，需要在安装过程中添加\"–with-google_perftools_module\"选项重新编译Nginx，安装代码如下: [root@localhostnginx-0.7.65]#./configure \\ >--with-google_perftools_module --with-http_stub_status_module --prefix=/opt/nginx [root@localhost nginx-0.7.65]#make [root@localhost nginx-0.7.65]#make install 到这里Nginx安装完成。 4.为google-perftools添加线程目录 创建一个线程目录，这里将文件放在/tmp/tcmalloc下，操作如下: [root@localhost home]#mkdir /tmp/tcmalloc [root@localhost home]#chmod 0777 /tmp/tcmalloc 5.修改Nginx主配置文件 修改nginx.conf文件，在pid这行的下面添加如下代码: #pid logs/nginx.pid; google_perftools_profiles /tmp/tcmalloc; 接着，重启Nginx，完成google-perftools的加载。 6.验证运行状态 为了验证google-perftools已经正常加载，通过如下命令查看: [root@ localhost home]# lsof -n | grep tcmalloc nginx 2395 nobody 9w REG 8,8 0 1599440 /tmp/tcmalloc.2395 nginx 2396 nobody 11w REG 8,8 0 1599443 /tmp/tcmalloc.2396 nginx 2397 nobody 13w REG 8,8 0 1599441 /tmp/tcmalloc.2397 nginx 2398 nobody 15w REG 8,8 0 1599442 /tmp/tcmalloc.2398 由于在Nginx配置文件中，设置worker_processes的值为4，因此开启了4个Nginx线程，每个线程会有一行记录。每个线程文件后面的数字值就是启动的Nginx的PID值。 至此，利用TCMalloc优化Nginx的操作完成。 Nginx内核参数优化 内核参数的优化，主要是在Linux系统中针对Nginx应用而进行的系统内核参数优化，常见的优化参数值如下。 下面给出一个优化实例以供参考: net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.ip_local_port_range = 1024 65000 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_syncookies = 1 net.core.somaxconn = 262144 net.core.netdev_max_backlog = 262144 net.ipv4.tcp_max_orphans = 262144 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_synack_retries = 1 net.ipv4.tcp_syn_retries = 1 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 30 将上面的内核参数值加入/etc/sysctl.conf文件中，然后执行如下命令使之生效: [root@ localhost home]#/sbin/sysctl -p 下面是对实例中选项的含义进行介绍： net.ipv4.tcp_max_tw_buckets参数用来设定timewait的数量，默认是180000，这里设为6000。 net.ipv4.ip_local_port_range选项用来设定允许系统打开的端口范围。 net.ipv4.tcp_tw_recycle选项用于设置启用timewait快速回收。 net.ipv4.tcp_tw_reuse选项用于设置开启重用，允许将TIME-WAIT sockets重新用于新的TCP连接。 net.ipv4.tcp_syncookies选项用于设置开启SYN Cookies，当出现SYN等待队列溢出时，启用cookies进行处理。 net.core.somaxconn选项默认值是128， 这个参数用于调节系统同时发起的tcp连接数，在高并发的请求中，默认的值可能会导致链接超时或者重传，因此，需要结合并发请求数来调节此值。 net.core.netdev_max_backlog选项表示当每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目。 net.ipv4.tcp_max_orphans选项用于设定系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤立连接将立即被复位并打印出警告信息。这个限制只是为了防止简单的DoS攻击。不能过分依靠这个限制甚至人为减小这个值，更多的情况是增加这个值。 net.ipv4.tcp_max_syn_backlog选项用于记录那些尚未收到客户端确认信息的连接请求的最大值。对于有128MB内存的系统而言，此参数的默认值是1024，对小内存的系统则是128。 net.ipv4.tcp_synack_retries参数的值决定了内核放弃连接之前发送SYN+ACK包的数量。 net.ipv4.tcp_syn_retries选项表示在内核放弃建立连接之前发送SYN包的数量。 net.ipv4.tcp_fin_timeout选项决定了套接字保持在FIN-WAIT-2状态的时间。默认值是60秒。正确设置这个值非常重要，有时候即使一个负载很小的Web服务器，也会出现因为大量的死套接字而产生内存溢出的风险。 net.ipv4.tcp_keepalive_time选项表示当keepalive启用的时候，TCP发送keepalive消息的频度。默认值是2（单位是小时）。 下面贴一个完整的内核优化设置: vi /etc/sysctl.conf CentOS5.5中可以将所有内容清空直接替换为如下内容: net.ipv4.ip_forward = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.default.accept_source_route = 0 kernel.sysrq = 0 kernel.core_uses_pid = 1 net.ipv4.tcp_syncookies = 1 kernel.msgmnb = 65536 kernel.msgmax = 65536 kernel.shmmax = 68719476736 kernel.shmall = 4294967296 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_sack = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_wmem = 4096 16384 4194304 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.core.netdev_max_backlog = 262144 net.core.somaxconn = 262144 net.ipv4.tcp_max_orphans = 3276800 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_synack_retries = 1 net.ipv4.tcp_syn_retries = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 30 net.ipv4.ip_local_port_range = 1024 65000 配置文件优化 基本优化 一般来说nginx 配置文件中对优化比较有作用的为以下几项： worker_processes 8; nginx 进程数，建议按照cpu 数目来指定，一般为它的倍数 (如,2个四核的cpu计为8)。 worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000; 为每个进程分配cpu，上例中将8 个进程分配到8 个cpu，当然可以写多个，或者将一 个进程分配到多个cpu。 worker_rlimit_nofile 65535; 这个指令是指当一个nginx 进程打开的最多文件描述符数目，理论值应该是最多打开文 件数（ulimit -n）与nginx 进程数相除，但是nginx 分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。详见 ulimit关于系统连接数的优化 现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 查看linux系统文件描述符的方法: [root@web001 ~]# sysctl -a | grep fs.file fs.file-max = 789972 fs.file-nr = 510 0 789972 use epoll; 使用epoll 的I/O 模型 ( 补充说明: 与apache相类，nginx针对不同的操作系统，有不同的事件模型 A）标准事件模型 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll B）高效事件模型 Kqueue：使用于 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X. 使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 Epoll: 使用于Linux内核2.6版本及以后的系统。 /dev/poll：使用于 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 Eventport：使用于 Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 ) worker_connections 65535; 每个进程允许的最多连接数， 理论上每台nginx 服务器的最大连接数为worker_processes*worker_connections。 keepalive_timeout 60; keepalive 超时时间。 client_header_buffer_size 4k; 客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 分页大小可以用命令getconf PAGESIZE 取得。 [ root@web001 ~]# getconf PAGESIZE 4096 但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为\"系统分页大小\"的整倍数。 open_file_cache max=65535 inactive=60s; 这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。 open_file_cache_valid 80s; 这个是指多长时间检查一次缓存的有效信息。 open_file_cache_min_uses 1; open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。 简单配置文件 下面是一个简单的nginx 配置文件: user www www; worker_processes 8; worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000; error_log /www/log/nginx_error.log crit; pid /usr/local/nginx/nginx.pid; worker_rlimit_nofile 204800; events { use epoll; worker_connections 204800; } http { include mime.types; default_type application/octet-stream; charset utf-8; server_names_hash_bucket_size 128; client_header_buffer_size 2k; large_client_header_buffers 4 4k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST:10m inactive=5m; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 4k; fastcgi_buffers 8 4k; fastcgi_busy_buffers_size 8k; fastcgi_temp_file_write_size 8k; fastcgi_cache TEST; fastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; fastcgi_cache_min_uses 1; fastcgi_cache_use_stale error timeout invalid_header http_500; open_file_cache max=204800 inactive=20s; open_file_cache_min_uses 1; open_file_cache_valid 30s; tcp_nodelay on; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; server { listen 8080; server_name backup.aiju.com; index index.php index.htm; root /www/html/; location /status { stub_status on; } location ~ .*\\.(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fcgi.conf; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ { expires 30d; } log_format access ‘$remote_addr — $remote_user [$time_local] \"$request\" ‘ ‘$status $body_bytes_sent \"$http_referer\" ‘ ‘\"$http_user_agent\" $http_x_forwarded_for'; access_log /www/log/access.log access; } } 关于FastCGI 的几个指令： fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST:10minactive=5m; 这个指令为FastCGI 缓存指定一个路径，目录结构等级，关键字区域存储时间和非活动删除时间。 fastcgi_connect_timeout 300; 指定连接到后端FastCGI 的超时时间。 fastcgi_send_timeout 300; 向FastCGI 传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI 传送请求的超时时间。 fastcgi_read_timeout 300; 接收FastCGI 应答的超时时间，这个值是指已经完成两次握手后接收FastCGI 应答的超时时间。 fastcgi_buffer_size 4k; 指定读取FastCGI 应答第一部分需要用多大的缓冲区，一般第一部分应答不会超过1k，由于页面大小为4k，所以这里设置为4k。 fastcgi_buffers 8 4k; 指定本地需要用多少和多大的缓冲区来缓冲FastCGI 的应答。 fastcgi_busy_buffers_size 8k; 这个指令我也不知道是做什么用，只知道默认值是fastcgi_buffers 的两倍。 fastcgi_temp_file_write_size 8k; 在写入fastcgi_temp_path 时将用多大的数据块，默认值是fastcgi_buffers 的两倍。 fastcgi_cache TEST 开启FastCGI 缓存并且为其制定一个名称。个人感觉开启缓存非常有用，可以有效降低CPU 负载，并且防止502 错误。 fastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; 为指定的应答代码指定缓存时间，如上例中将200，302 应答缓存一小时，301 应答缓存1 天，其他为1 分钟。 fastcgi_cache_min_uses 1; 缓存在fastcgi_cache_path 指令inactive 参数值时间内的最少使用次数，如上例，如果在5 分钟内某文件1 次也没有被使用，那么这个文件将被移除。 fastcgi_cache_use_stale error timeout invalid_header http_500; 不知道这个参数的作用，猜想应该是让nginx 知道哪些类型的缓存是没用的。以上为nginx 中FastCGI 相关参数，另外，FastCGI 自身也有一些配置需要进行优化，如果你使用php-fpm 来管理FastCGI，可以修改配置文件中的以下值： 60 同时处理的并发请求数，即它将开启最多60 个子线程来处理并发连接。 102400 最多打开文件数。 204800 每个进程在重置之前能够执行的最多请求数。 ulimit关于系统连接数的优化 linux 默认值 open files 和 max user processes 为 1024 #ulimit -n 1024 #ulimit –u 1024 问题描述： 说明 server 只允许同时打开 1024 个文件，处理 1024 个用户进程 使用ulimit -a 可以查看当前系统的所有限制值，使用ulimit -n 可以查看当前的最大打开文件数。 新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files 。因此，需要将其改大。 解决方法： 使用 ulimit –n 65535 可即时修改，但重启后就无效了。（注ulimit -SHn 65535 等效 ulimit -n 65535 ，-S 指soft ，-H 指hard) 修改方式 有如下三种修改方式： 在/etc/rc.local 中增加一行 ulimit -SHn 65535 在/etc/profile 中增加一行 ulimit -SHn 65535 在/etc/security/limits.conf 最后增加: * soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 具体使用哪种，在 CentOS 中使用第1 种方式无效果，使用第3 种方式有效果，而在Debian 中使用第2 种有效果 # ulimit -n 65535 # ulimit -u 65535 备注：ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制 soft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。 soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值。","tags":"高性能","title":"Nginx打造3w高并发网站"},{"url":"/python-pyenv.html","text":"需要使用新版本Python的相关功能，但是又不想要影响到系统自带的Python，这个时候就需要实现Python的多版本共存。 pyenv 可以很好的实现Python的多版本共存。 安装pyenv 1 2 3 4 5 $ git clone git://github.com/yyuu/pyenv.git ~/.pyenv $ echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc $ echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc $ echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc $ exec $SHELL -l 安装Python 查看可安装的版本 1 $ pyenv install --list 安装指定版本 使用如下命令即可安装python 3.3.2. 1 $ pyenv install 3.3.2 该命令会从github上下载python的源代码，并解压到/tmp目录下，然后在/tmp中执行编译工作。编译过程依赖一些其他的库文件，若库文件不能满足，则编译错误，需要重新下载、编译。。。(为什么每次都要重新下呢？) 已知的一些需要预先安装的库包括： readline readline-devel readline-static openssl openssl-devel openssl-static sqlite-devel bzip2-devel bzip2-libs 在所有python依赖库都安装好的情况下，python的安装很顺利。 更新数据库 安装完成之后需要对数据库进行更新： 1 $ pyenv rehash 查看当前已安装的python版本 1 2 3 $ pyenv versions * system ( set by /export/home/seisman/.pyenv/version ) 3.3.2 其中的星号表示使用的是系统自带的python。 设置全局的python版本 1 2 3 4 $ pyenv global 3.3.2 $ pyenv versions system * 3.3.2 ( set by /export/home/seisman/.pyenv/version ) 当前全局的python版本已经变成了3.3.2。也可以使用 pyenv local 或 pyenv shell 临时改变python版本。 确认python版本 1 2 3 4 5 $ python Python 3.3.2 ( default, Sep 30 2013, 20:11:44 ) [ GCC 4.4.7 20120313 ( Red Hat 4.4.7-3 )] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> 使用python 输入 python 即可使用新版本的python； 系统命令会以/usr/bin/python的方式直接调用老版本的python； 使用pip安装第三方模块时会安装到~/.pyenv/versions/3.3.2下，不会和系统模块发生冲突。","tags":"Python","title":"Python多版本共存之pyenv"},{"url":"/shi-yong-vagrantda-zao-ni-de-xu-ni-huan-jing.html","text":"使用Vagrant打造你的虚拟环境 因为要做mongDB的replication+sharding的实验，领导给我推荐Vagrant来模拟虚拟环境做部署实践，稍微了解够大为震惊，因网上文档不是特别容易理解，留下一份以备后用 vagrant的强大在于是一个镜像，配置完以后镜像可以放到任何地方去，真正做到了一劳永逸了。 总结一下自己使用vagrant的一点笔记，以免以后忘记还得再去翻官方文档。 vagrant的官方网站：http://www.vagrantup.com/ 现在又改版了，挺漂亮的。 vagrant的一些镜像：http://www.vagrantbox.es/ 各种linux都有。 然后按照官方说的，执行这三部，然后一个虚拟机就起来了。 注：先要安装VirtualBox 配置box $ vagrant box add debian http://ergonlogic.com/files/boxes/debian-current.box #增加一个box,debian就是box的title 后面跟vagrant上的virtualbox镜像地址 $ vagrant init debian #初始化debian $ vagrant up #这个是真正的启动 注意国内网速访问很慢 这里可以先去 http://www.vagrantbox.es/ 下载你需要的镜像 然后把http那行直接换成你本地镜像的路径就ok比较方便和快捷 连接虚拟主机 你会看到终端显示了启动过程，启动完成后，我们就可以用 SSH 登录虚拟机了，剩下的步骤就是在虚拟机里配置你要运行的各种环境和参数了。 $ vagrant ssh # SSH 登录 ssh的后面可以跟你的title来连接不同的vm主机 打包分发 当你配置好开发环境后，退出并关闭虚拟机。在终端里对开发环境进行打包： $ vagrant package 打包完成后会在当前目录生成一个 package.box 的文件，将这个文件传给其他用户，其他用户只要添加这个 box 并用其初始化自己的开发目录就能得到一个一模一样的开发环境了。 常用命令 $ vagrant init # 初始化 $ vagrant up # 启动虚拟机 $ vagrant halt # 关闭虚拟机 $ vagrant reload # 重启虚拟机 $ vagrant ssh # SSH 至虚拟机 $ vagrant status # 查看虚拟机运行状态 $ vagrant destroy # 销毁当前虚拟机 box管理 $vagrant box list $vagrant box add $vagrant box remove 更多内容请查阅官方文档 http://docs.vagrantup.com/ Multi-VM 多虚拟机 VAGRANTFILE_API_VERSION = \"2\" #定义版本 Vagrant.configure ( VAGRANTFILE_API_VERSION ) do | config | #使用内部2版本 config.vm.define :debian1 do | debian1 | #定义第一台虚拟机，||里面就类似一个变量设置参数时使用 debian1.vm.box = \"debian1\" #设置box名为debian1 debian1.vm.host_name = \"debian1\" #设置hostname为debian1 debian1.vm.network :private_network, ip: \"192.168.1.11\" #设置网络为内部网络 ip为192.168.1.11 end config.vm.define :debian2 do | debian2 | debian2.vm.box = \"debian2\" debian2.vm.host_name = \"debian2\" debian2.vm.network :private_network, ip: \"192.168.1.12\" end config.vm.define :debian3 do | debian3 | debian3.vm.box = \"debian3\" debian3.vm.host_name = \"debian3\" debian3.vm.network :private_network, ip: \"192.168.1.13\" end end 注意语法格式就好，配置前关闭虚拟机，配置完后打开虚拟机。 注意事项 使用 Apache/Nginx 时会出现诸如图片修改后但页面刷新仍然是旧文件的情况，是由于静态文件缓存造成的。需要对虚拟机里的 Apache/Nginx 配置文件进行修改： Apache 配置添加: EnableSendfile off Nginx 配置添加: sendfile off ;","tags":"虚拟机","title":"使用Vagrant打造你的虚拟环境"},{"url":"/zabbixjian-kong-mongodb.html","text":"zabbix监控mongoDB 推荐文档： 官方推荐：http://docs.mongodb.org/manual/administration/monitoring/ 因我使用的是zabbix.所以选择： https://code.google.com/p/mikoomi/wiki/03 插件下载地址： http://mikoomi.googlecode.com/svn/plugins/MongoDB%20Plugin/ 学习地址： https://blog.serverdensity.com/mongodb-monitoring-db-serverstatus/ http://www.yaukb.com/2012/05/zabbix_mongodb/ 1.在Zabbix Server上安装php MongoDB驱动： [root@localhost conf.d]# pecl install mongo WARNING: channel \"pecl.php.net\" has updated its protocols, use \"pecl channel-update pecl.php.net\" to update downloading mongo-1.4.3.tgz … Starting to download mongo-1.4.3.tgz (140,481 bytes) …………………………done: 140,481 bytes 84 source files, building running: phpize Configuring for: PHP Api Version: 20100412 Zend Module Api No: 20100525 Zend Extension Api No: 220100525 …… Build process completed successfully Installing ‘/usr/lib64/php/modules/mongo.so' install ok: channel://pecl.php.net/mongo-1.4.3 configuration option \"php_ini\" is not set to php.ini location You should add \"extension=mongo.so\" to php.ini You have new mail in /var/spool/mail/root [root@localhost conf.d]# vim /etc/php.ini [root@localhost conf.d]# /etc/init.d/httpd reload [root@localhost conf.d]# php -m |grep mongo mongo 2.下载： [root@localhost externalscripts]# pwd /etc/zabbix/externalscripts [root@localhost externalscripts]# wget http://mikoomi.googlecode.com/svn/plugins/MongoDB%20Plugin/mikoomi-mongodb-plugin.php [root@localhost externalscripts]# wget http://mikoomi.googlecode.com/svn/plugins/MongoDB%20Plugin/mikoomi-mongodb-plugin.sh 3.导入模板 建立主机： 将MongoDB_Plugin_template_export.xml导入到zabbix中 修改\"Miscellaneous: Data Collector\"监控项的key值，因默认提供的值有错误： mikoomi-mongodb-plugin.sh[\"--\", \"-h\", \"{$MONGODB_HOSTNAME}\", \"-p\", \"{$MONGODB_PORT}\", \"-z\", \"{$MONGODB_ZABBIX_NAME}\"] 在zabbix里建立主机，定义宏： {$MONGODB_HOSTNAME} = 10.0.199.30 #即ip地址 {$MONGODB_PORT} = 27017 #监控mongdb的端口号 {$MONGODB_ZABBIX_NAME} =MongDB1 #hostname 就是主机名 不要写显示名 这样会接受不到数据 一定是hostname 然后给主机连接上模板即可。 4.测试： [root@localhost externalscripts]# ./mikoomi-mongodb-plugin.sh -D -h10.0.199.30 -p27017 -z MongDB1 0 [root@localhost externalscripts]# less /tmp/mikoomi-mongodb-plugin.php_MongoDB1.log mikoomi-mongodb-plugin.php:Successfully connected to mongoDB using connect string root:passworda@MongDB1:27017 zabbix_sender [8413]: Warning: [line 66] ‘Key value' required zabbix_sender [8413]: Warning: [line 68] ‘Key value' required zabbix_sender [8414]: DEBUG: answer [{ \"response\":\"success\", \"info\":\"Processed 58 Failed 13 Total 71 Seconds spent 0.001618\"}] sent: 71; skipped: 2; total: 73 /tmp/mikoomi-mongodb-plugin.php_MongDB1.log (END) 若出现 Failed 的数目和 Total数目相等的话 应该是 mikoomi-mongodb-plugin.sh 后面-z参数的 hostname没写对 这个hostname是zabbix主机的hostname即主机名 而不是显示名","tags":"监控","title":"zabbix监控mongoDB"},{"url":"/githubpelican.html","text":"使用github和pelican搭建本站博客 安装virtualenv虚拟环境 安装虚拟环境是为了防止污染，linux本身的python环境 easy_install virtualenv 使用virtualenv virtualenv pelican #创建虚拟环境 cd pelican source bin/activate #激活虚拟环境 安装pelican和markdown pelican 就是生成静态博客的程序 markdow 是写博客使用的轻量级标记语言,不会使用的同学可以查看 帮助 $ pip install pelican $ pip install Markdown $ pip install ghp-import 建立blog目录 $ mkdir myblog $ cd myblog 开始创建 $ pelican-quickstart 基本按照提示设置就可以，稍后可以在pelicanconf.py文件中手动修改。 . | -- content #所有文章放于此目录 | -- develop_server.sh #用于开启测试服务器 | -- Makefile #方便管理博客的Makefile | -- output #静态生成文件 | -- pelicanconf.py #配置文件 | -- publishconf.py #配置文件 写一篇文章 在 content 目录新建一个 test.md 文件, 填入一下内容: Title: 文章标题 Date: 2013-04-18 Category: 文章类别 Tag: 标签1, 标签2 这里是内容 然后执行: make html 用以生成html 然后执行 ./develop_server.sh start 开启一个测试服务器, 这会在本地 8000 端口建立一个测试web服务器, 可以使用浏览器打开: http://localhost:8000 来访问这个测试服务器, 然后就可以欣赏到你的博客了 Github上的准备 在Github上创建一个新项目，把这个项目clone到myblog文件夹下。然后按照Github的规定建立一个没有父节点的分支gh-pages。 注：在是用分支创建github的blog的时候，要先确保自己的github上有例如：zbing3.github.io命名的项目并且在 settings 中开启Github Pages 如图： 点击 Automatic Page Generator 开启Github Pages服务 进入output目录中： $ git init $ git checkout --orphan gh-pages $ git add . $ git commit -m \"first post\" $ git remote add origin git@github.com:zbing3/opslinux.git $ git push origin gh-pages 这样上传完代码等10分钟左右，即可在浏览器中使用 http://zbing3.github.io/myblog 就能访问到自己的博客 定制自己的Makefile文件，让git提交更方便一点 使用此方法就不用在output目录中初始git了。编辑Makefile vim Makefile ，在github下面添加如下格式的文件： pip install ghp - import git : $ ( PELICAN ) $ ( INPUTDIR ) - o $ ( OUTPUTDIR ) - s $ ( CONFFILE ) $ ( PELICANOPTS ) ghp - import $ ( OUTPUTDIR ) git push origin gh - pages ghp-import 是用来Easily import docs to your gh-pages branch，就是方便添加到gh-pages分支的，这个分支github才能解析我们的html嘛。 接着以后： make git 就可以直接提交到git的gh-pages分支的 pelican的备份 因为有时候要换电脑，所以肯定要把你的pelican的博客环境做备份，以便换完电脑后快速的搭建出写博客的环境 进入blog目录： $ git branch #查看本地分支，没有master所以要创建 如果有master就跳过创建 gh-pages $ git branch master #创建master分支 $ git checkout master #切换到master分支 $ git add . $ git commit -m \"first post\" $ git remote add origin git@github.com:zbing3/opslinux.git #添加过origin就不用添加 $ git push origin master #有事提交报错，如因原来提交过master分支起冲突，就在后面追加--froce 未完待续……","tags":"pelican","title":"使用github和pelican搭建本站博客"},{"url":"/helloworld.html","text":"总想找个地方写博客，分享下自己所学的东西，原来因为种种原因一直没坚持下来，这次用了github和pelican搭建了个静态博客，使用git上传真的很爽，就是markdown这玩应我不是太会用，还的慢慢学学，大家都说他好用，我也不知道到为什么，学着看吧与大家共勉，开源世界的软件，总能给人们带来美好的东西。","tags":"随笔","title":"helloworld"},{"url":"/links.html","text":"晓的博客 峰云就她了 峰云就她了-51cto 灿哥的Blog the5fire的技术博客 FURION'S BLOG-思聪 陈李粮 流水理鱼-李爽 我友博客 Reboot运维开发","tags":"misc","title":"links"}]}